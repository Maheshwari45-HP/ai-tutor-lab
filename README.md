# ğŸ§  AI Tutor Lab â€” MVP

A **minimal local implementation** of the **Autonomous AI Tutor Orchestrator** â€” combining a **FastAPI backend**, **Streamlit frontend**, and a **mock MCP server** for rapid prototyping and hackathon demos.

Empowers students and educational platforms with **autonomous multi-tool AI orchestration**.

---

## ğŸ“‚ Project Structure

ai-tutor-lab/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/                 # FastAPI app modules
â”‚   â”œâ”€â”€ .env                 # Environment variables
â”‚   â”œâ”€â”€ requirements.txt     # Backend dependencies
â”‚   â””â”€â”€ run_backend.bat      # Run backend + MCP mock
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ streamlit_app.py     # Streamlit UI
â”‚   â”œâ”€â”€ .env                 # Environment variables
â”‚   â””â”€â”€ requirements.txt     # Frontend dependencies
â”œâ”€â”€ run_local.bat            # Start backend + frontend
â””â”€â”€ LICENSE.txt              # Custom license (All Rights Reserved)


## âš¡ Quick Start (Windows)

### 1ï¸âƒ£ Setup Virtual Environments (Recommended)

```bat
python -m venv venv_backend
python -m venv venv_frontend
```

Activate the environment before installing dependencies.

---

### 2ï¸âƒ£ Install Dependencies

```bat
pip install -r backend/requirements.txt
pip install -r frontend/requirements.txt
```

---

### 3ï¸âƒ£ Start Services

* **Run both together:**

```bat
run_local.bat
```

* **Or individually:**

```bat
backend\run_backend.bat   # Starts MCP mock + FastAPI backend
frontend\run_frontend.bat # Starts Streamlit frontend
```

---

### 4ï¸âƒ£ Access the Frontend

Open your browser at:
[http://localhost:8501](http://localhost:8501)

---

## âš™ï¸ Configuration

* **Environment Variables:**
  `.env` files contain placeholders like:

  ```
  OPENAI_API_KEY=your_key_here
  ```

  Replace with your actual keys for real service integration.

* **MCP (Model Context Protocol):**

  * Local mock server URL: `http://localhost:8001/mcp/process`
  * Backend automatically falls back to a **local simple plan** if MCP is unreachable.

* **LangGraph:**
  Calls are currently mocked in `langgraph_wrapper.py`. Replace with real API calls for full functionality.

---

## ğŸ› ï¸ Key Components

| File                               | Purpose                           |
| ---------------------------------- | --------------------------------- |
| `backend/app/orchestrator.py`      | Core orchestration logic          |
| `backend/app/mcp_client.py`        | MCP client wrapper                |
| `backend/app/langgraph_wrapper.py` | LangGraph API wrapper (mocked)    |
| `frontend/streamlit_app.py`        | Streamlit UI for user interaction |

---

## ğŸ§© Workflow Overview

1. **Student Input:** Text, file, or question submitted.
2. **AI Tutor LLM:** Understands intent & context.
3. **Context Analyzer:** Extracts key parameters.
4. **Parameter Extractor & Validator:** Converts input into structured tool parameters.
5. **Tool Handler (MCP):** Routes parameters to appropriate educational tools.
6. **LangGraph Workflow:** Dynamically manages multi-tool workflows.
7. **Tool Execution:** Generates quizzes, summaries, or explanations.
8. **LLM Post-Processing:** Integrates outputs into coherent response.
9. **Response Delivery:** Displayed on Streamlit UI.
10. **Logging & Feedback:** Stores session for adaptive learning and analytics.

---


---

## ğŸ§  Vision

1.Personalized AI tutoring powered by modular AI orchestration
2.Local-first development for privacy and speed
3.Expandable to real LangGraph or MCP workflows
---

ğŸ“œ License
All Rights Reserved Â© 2025 Maheshwari Khobare
This repositoryâ€™s content may not be reproduced or distributed without written permission.

